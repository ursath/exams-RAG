# Main Memory

## _Background de Arqui_

La memoria es un largo arreglo de bytes, cada slot corresponde a una direcci√≥n de memoria. La CPU tomaba de memoria una instrucci√≥n de acuerdo al valor de RIP, la instrucci√≥n se decodifica para posteriormente ejecutarla.

Los registros de CPU, que son built in, pueden ser accedidos de manera directa en un ciclo de CPU por la misma CPU. En cambio, para acceder a la memoria, si o si tenemos que usar los buses de datos y la operaci√≥n puede tardar varios ciclos de CPU. Para esos casos, el procesador necesita detenerse, ya que no tiene los datos necesarios para completar lo que la instrucci√≥n indica. Como esto es inaceptable en t√©rminos de eficiencia (ya que el tiempo de respuesta de la memoria es alto), es que se puso una cache en medio del procesador y la memoria f√≠sica. Esta tenia mayor velocidad de respuesta que la memoria f√≠sica.

Sin embargo, el bloqueo de memoria no se soluciona para todos los casos con la cache. La cache almacena los ‚Äùbloques mas consultados‚Äù para evitar la constante b√∫squeda en memoria de ciertos datos. ¬øPero si el ‚Äúbloque de memoria‚Äù que solicitamos no esta en la cache? ¬øTenemos el mismo problema, no? Si, es verdad, pero recordemos del apunte anterior que durante un bloqueo de memoria, si llegamos a tener un _multithreaded core_ podemos _switchear_ el _hardware thread_ estancado por otro _hardware thread_.

No solo nos interesa la velocidad relativa para acceder a la memoria f√≠sica, sino que tambi√©n su protecci√≥n. No queremos que un proceso de usuario pueda acceder impunemente al Kernel Space o que un proceso de usuario pueda matar a otro proceso de usuario libremente. ¬øQuien puede proveer esta protecci√≥n? El hardware. Esto se debe a que el sistema operativo no suele intervenir entre la CPU y sus accesos de memoria.

Recordemos tambi√©n de manera general el mapeo de direcci√≥n l√≥gica (o virtual) a direcci√≥n f√≠sica. El usuario nunca programa en direcciones f√≠sicas, sino que son direcciones virtuales. Esto ultimo se logra gracias a la MMU y de alguna manera, protege a la memoria de las malas intenciones del usuario. Como nosotros trabajamos siempre en modo flat en procesadores de Intel, podemos resumir la transformaci√≥n de la siguiente manera:

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8a25c55d-1103-48ec-abdb-4fe9e67dcf2d/Untitled.png)

_Otro m√©todo de protecci√≥n de la memoria:_

Cuando el _scheduler_ selecciona un proceso para su ejecuci√≥n, el dispatcher carga los registros de _relocation_ y _limit_ correspondientes como parte del context switch. Debido a que cada direcci√≥n que se esta por ejecutar se compara con estos registros, podemos proteger tanto el sistema operativo como los programas y datos de los otros usuarios de ser modificados por este proceso en ejecuci√≥n.

# Memory Allocation

## _Variable partition_

Una forma sencilla de asignar memoria a un proceso, es darle pedazos de memoria de tama√±o variable. Cada partici√≥n o pedazo puede contener exactamente 1 proceso.

El sistema operativo hace uso de una tabla (lista) que contiene la informaci√≥n de las porciones de memoria ocupadas y desocupadas y sus tama√±os. Inicialmente, toda la memoria (menos la zona donde se ubico el SO) esta disponible para procesos de usuario.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a5eff975-ea3a-4b58-b2e5-4e299680170f/Untitled.png)

Si la zona de memoria que le asigno a un proceso para que corra es muy grande, esta se parte en dos. Una de las dos es asignada al proceso y la otra parte queda libre. Los agujeros contiguos de memoria se transforman en un solo bloque de memoria disponible.

**¬øQue hacemos si un proceso no entra? ¬øRechazamos al proceso y listo?**

Es una opci√≥n mientras que respondamos con un mensaje de error adecuado. Sin embargo, una alternativa es utilizar una cola donde en cada asignaci√≥n de un slot de memoria, el SO chequee si el proceso que esta esperando primero en la cola entra en alguno de los slots de memoria libres.

Existen varios algoritmos o estrategias para seleccionar un pedazo de memoria libre de un conjunto de pedazos de memoria libres:

- First Fit
    
    Asigna memoria del primer hueco que encuentre que es suficientemente grande para el proceso. La b√∫squeda puede comenzar desde el principio del conjunto (lista) de pedazos de memoria libres o desde donde haya terminado la anterior ejecucion del algoritmo. Podemos finalizar la b√∫squeda cuando hayamos encontrado un pedazo de memoria lo suficientemente grande.
    
- Best Fit
    
    Asigna el pedazo de memoria mas chico que sea suficientemente grande para el proceso. Se busca en toda la lista a no ser que este ordenada por tama√±o.
    
- Worst Fit
    
    Asigna el pedazo de memoria mas grande. Se busca en toda la lista a no ser que esta ordenada por tama√±o.
    

<aside> ‚ÄºÔ∏è El mas r√°pido es first fit.

</aside>

# Fragmentaci√≥n de la memoria

Tanto _best fit_ como _first fit_ sufren de lo que se llama _external fragmentation_.

- A medida que los procesos se cargan y se eliminan de la memoria, el espacio de memoria libre se divide en peque√±os pedazos. En otras palabras, los espacios de memoria libre no son contiguos.
- En el peor caso, podemos tener un bloque de memoria libre (perdida) entre medio de dos procesos. Si todos estos pedacitos libres fueran un solo bloque, podr√≠amos correr procesos mas pesados o incluso mas procesos.

As√≠ como existe la fragmentaci√≥n externa, existe la fragmentaci√≥n interna. Esta es memoria asignada a un proceso que sobra, es decir, memoria no utilizada interna a la partici√≥n.

**Soluciones a la fragmentaci√≥n externa**

_Compactaci√≥n_. La idea es organizar al contenido de la memoria de tal forma que quede la division bien marcada entre memoria ocupada y memoria libre. Solo es posible llevarla acabo si la realocacion es din√°mica y se lleva acabo en tiempo de ejecuci√≥n. Por lo general esta operaci√≥n tiene una complejidad temporal alta.

_Paginaci√≥n:_ es mejor que la compactaci√≥n ya **que permite que el espacio de direcciones f√≠sicas de un proceso no sea contiguo en memoria. La paginaci√≥n se implementa a trav√©s de la cooperaci√≥n entre el sistema operativo y el hardware de la computadora. Es evidente que la paginaci√≥n no resuelve la fragmentaci√≥n interna.

# Paginaci√≥n

## Overview

La RAM se divide en particiones de igual tama√±o y se los denomina _marcos_. A la memoria virtual se la divide en _paginas_ de igual tama√±o. Ambos t√≠picamente coinciden en su valor. Cuando un proceso se ejecuta, sus paginas se cargan en un marco en memoria RAM.

La direction l√≥gica podia contener subdivisiones, la mas sencilla es un numero de pagina y un offset. La primera division nos sirve como √≠ndice para acceder a la tabla de paginas donde obtenemos un puntero a la base del marco. Si a la base del marco le sumamos el offset, obtenemos la posici√≥n relativa dentro del marco. La combinaci√≥n de ambos punteros b√°sicamente nos da como resultado una posici√≥n en memoria RAM.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/93a0dc83-c414-47d4-9e39-1b89c3bbc24d/Untitled.png)

_La MMU realiza los siguientes pasos para realizar el mapeo:_

1. Toma de la direcci√≥n l√≥gica el numero de pagina y lo usa como un √≠ndice en la tabla de paginas
2. Extrae de la tabla de paginas el numero de marco asociado al numero de pagina del paso uno
3. Reemplaza el numero de pagina del item uno por el numero de marco en la direcci√≥n l√≥gica

## Hardware Support

En el contexto de cada proceso, adem√°s de preservar los registros, flags, etc, tambi√©n almacenamos un puntero a su tabla de paginas. Luego de un context switch, se restauran los registros y el valor de `PTBR` (_page-table-base register_) con el puntero a la tabla de paginas correspondiente.

El problema de esto ultimo, es que estamos realizando dos accesos a memoria:

- Uno para ir a buscar el numero de marco a la tabla de paginas
- Uno para acceder a la zona de memoria una vez combinados el numero de marco y offset

_**Soluci√≥n:**_ translation look-aside buffer **(TLB)**

La TLB es una especie de memoria cache que esta del lado del procesador y que es consultada por la MMU previo a hacer un acceso de memoria.

La TLB contiene en sus entradas algunas tablas de paginas. Cuando una direcci√≥n l√≥gica llega a la MMU, esta ultima primero chequea si el numero de pagina esta en la TLB. Si esta, el numero de marco se obtiene al instante y se usa para acceder a memoria. Si se produce un _TLB miss_ porque la pagina no esta disponible en la TLB, se procede como en la imagen anterior y adem√°s se quita una entrada de la TLB para agregar el numero de marco recientemente accedido (pol√≠tica LRU o RR). La TLB permite que ciertas entradas no puedan ser removidas. Esto ultimo se suele aprovechar para las entradas del Kernel.

La TLB adem√°s almacena en sus entradas un _address-space identifier_ (ASIDs). Esto permite identificar un√≠vocamente a un proceso. Entonces, antes de acceder a cualquier marco, la TLB se asegura de que el proceso que est√° corriendo y pidi√≥ dicho marco coincidan en el campo ASID.

<aside> ‚ÄºÔ∏è Ante un cambio de contexto, debemos borrar toda la TLB. Ver ejercicio de la guia.

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4a3111fb-6eed-4081-90ec-ce1deb47a916/Untitled.png)

## _Protecci√≥n_

Cada marco tiene una serie de bits que permite su protecci√≥n. Estos bits est√°n presentes en la tabla de p√°ginas.

- Bit de escritura
- Bit de lectura
- Bit de ejecuci√≥n
- Bit de presencia asociado con Swapping (esto lo setea el SO)
    - Puede ocurrir que un proceso, tenga un n√∫mero de marco que no est√© presente en memoria, eso implica que el bit $P=0$. La MMU, que es parte del procesador, genera una excepci√≥n que la maneja el SO para traer de disco dicha p√°gina.
- Bit de v√°lido o inv√°lido (esto lo setea el SO)
    - Indica si este marco puede ser accedido por el proceso que esta corriendo. Si es valido, significa que la p√°gina pertenece a dicho proceso. Si es inv√°lido es lo contrario.

## _Shared Pages_

Una librer√≠a de C puede ser requerida por m√∫ltiples procesos. Se conoce como _reentrant code_ a aquella porci√≥n de c√≥digo que no se modifica durante la ejecuci√≥n. Gracias a esa caracter√≠stica, distintos procesos pueden correr el mismo c√≥digo sin necesidad de tener que copiarlo en sus direcciones virtuales.

Basta con una copia de la librer√≠a en memoria RAM y que todos los procesos que necesiten de dicha librer√≠a tengan en su tabla de p√°ginas un puntero a esta copia en RAM.

## _Structure of the page table_

Hablaba de distintas formas de organizar la tabla de p√°ginas, no me parecio importante porque nunca hablamos de nada distinto a lo que vimos en Arqui.

# Swapping

Una p√°gina puede pasar de RAM a disco o viceversa. Esto permite confrontar el hecho de que la memoria virtual supere a la memoria RAM en cantidad de direcciones.

**Swap out:** mover un proceso entero a disco (no entra a la cola de listos).

**Swap in:** mueve el proceso de disco a la cola de listos.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/67ddab7f-733d-4166-b300-e8661d56ecf7/Untitled.png)

## _Swapping with pages_

**Page out:** p√°gina de memoria a disco.

**Page in:** p√°gina de disco a memoria.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e0c5f1a9-ca51-48f3-92f7-e67b7aa4a101/Untitled.png)

Veremos m√°s adelante el costo que tiene mover una p√°gina al disco de memoria virtual y como podemos evitar mover p√°ginas a disco de manera innecesaria (bit dirty).

# Introducci√≥n

Hasta ahora, introducimos ciertas estrategias de manejo de memoria RAM. Vimos que el objetivo de todas ellas es mantener a los procesos en memoria RAM permitiendo la ejecuci√≥n concurrente o intercalada de dos o m√°s programas en un solo core. El problema es que todas las estrategias mencionadas tienden a necesitar que todo el proceso debe estar cargado en RAM para comenzar a ejecutar.

Para solucionar esto nace la t√©cnica de la memoria virtual que permite ejecutar procesos que no est√©n completamente en RAM. La ventaja de esta estrategia es que ahora nuestros programas pueden ser mas grandes que la memoria f√≠sica. Es decir, el programador se puede abstraer del concepto de memoria RAM pensando que es un arreglo de almacenamiento extremadamente grande y uniforme.

La memoria virtual permite entre otras cosas:

- Que los procesos compartan archivos y librer√≠as
- Que hagan uso de la shared memory
- Provee un mecanismo eficiente para crear procesos

Desventajas:

- Dif√≠cil de implementar
- Puede reducir la performance de la PC si se usa descuidadamente

<aside> ‚ÄºÔ∏è La memoria virtual pensemosla como el disco. Mas adelante veremos que el acceso a este disco tiene un determinado tiempo de acceso.

</aside>

# Background

Los algoritmos que presentamos en el apunte anterior cumplen un prop√≥sito indispensable: ubicar instrucciones en memoria RAM para que puedan ser ejecutadas.

Lo que no mencionamos en el apunte anterior es que es algo descabellado ubicar todo el proceso en memoria f√≠sica para comenzar a correrlo. Pensemos lo siguiente:

- Los programas por lo general tienen handlers de excepciones que casi nunca suelen ser ejecutados
- An√°logamente, existen rutinas o funciones que quiz√°s nunca se ejecuten
- Las listas, arreglos y otras estructuras ocupan mas memoria que la que solemos especificarle cuando codeamos

**El punto es el siguiente:** si bien es cierto que estas partes del programa son importantes, lo mas probable es que no se necesite todo al mismo tiempo.

**¬øY si pusi√©ramos programas de manera parcial en memoria?**

- Un programa no estar√≠a restringido a la cantidad de memoria f√≠sica en el sistema. Los usuarios podr√≠an tener programas que ocupen muchas direcciones virtuales.
- Como ahora tenemos m√°s espacio ya que estamos ubicando porciones de programas, podemos hacer un mejor uso de la memoria RAM y ubicar mas porciones de otros procesos en ella. Esto aumenta la utilizaci√≥n de la CPU y el throughput.
- Se necesitar√≠a menos tiempo de E/S para cargar o intercambiar partes de programas en la memoria, por lo que cada programa se ejecutar√≠a m√°s r√°pido

<aside> ‚ÄºÔ∏è Poner a los programas de manera parcial en memoria beneficia tanto al sistema como al usuario.

</aside>

**¬øQue es la memoria virtual?**

La memoria virtual es un mecanismo que permite marcar la separaci√≥n entre direcciones l√≥gicas y direcciones f√≠sicas. Como mencionamos, la idea es proporcionar un espacio de direcciones virtuales (direcciones l√≥gicas) que sea superior (o igual) a los direcciones f√≠sicas presentes en el sistema. Con esto podemos lograr que el programador se deje de preocupar de la cantidad de memoria f√≠sica presente en el sistema y que pueda programar con tranquilidad.

<aside> ‚ÄºÔ∏è Decimos que cada proceso tiene su espacio o frame de direcciones virtuales o l√≥gicas y est√°n contiguas en memoria virtual.

</aside>

La idea es dividir tanto a la memoria virtual como a la f√≠sica en paginas de igual tama√±o y que la MMU se encargue de hacer el mapeo correspondiente. Recordemos que en memoria f√≠sica no necesariamente los procesos pueden quedar contiguos si utilizamos el mecanismo de paginacion.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8cc74668-828e-4f46-97d0-b6d9f5297bc8/Untitled.png)

- Proceso en memoria virtual - _Sparse Address Spaces_
    
    Supongamos que tenemos el siguiente proceso en memoria virtual. El heap crece para las direcciones mas altas y el stack en sentido contrario. Ese espacio en azul, corresponde a direcciones virtuales ‚Äúlibres‚Äù que pueden ser utilizadas por uno u otro.
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ffef1bd9-14fc-4409-8e25-531976647784/Untitled.png)
    
    A los espacios de direcciones virtuales con agujeros se los conoce como _sparse address spaces_. Es beneficioso utilizar estos tipos de espacios virtuales por el hecho de que estamos permiti√©ndole al proceso a√±adir direcciones virtuales tanto para stack o heap si quisi√©ramos. Mas interesante aun, podemos asignar dichas direcciones virtuales al linkeo de librer√≠as (ver shared libraries del apunte anterior) o una shared memory (utilizando _mmap_) durante la ejecuci√≥n de un programa. Incluso durante un _fork_, las paginas del proceso padre e hijo se comparten inicialmente.
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6d181d6f-f62a-4e61-a729-b8a8d8fc0856/Untitled.png)
    

# Paginaci√≥n por demanda

La idea es cargar p√°ginas de memoria virtual a f√≠sica √∫nicamente cuando sean necesarias. En otras palabras, una p√°gina se carga en memoria cuando un programa la demanda mientras se esta ejecutando. La idea es que las p√°ginas que no son accedidas o demandadas, no estar√°n ocupando espacio en memoria f√≠sica.

Esta t√©cnica es muy parecida al sistema de paginaci√≥n con _swapping_ que mencionamos en el apunte anterior donde un proceso reside en un storage secundario (HDD).

## _Conceptos b√°sicos_

Como mencionamos, las p√°ginas que son demandadas durante la ejecuci√≥n se cargan en memoria y el resto quedan en un storage secundario.

**¬øComo hacemos para distinguir de que proceso es cada p√°gina? ¬øComo sabemos que una p√°gina esta en memoria f√≠sica o en disco?**

Con el bit de valid-invalid, o bit de presencia, que vimos en el apunte anterior.

- Si el bit vale 1, la p√°gina asociada es v√°lida y est√° en memoria RAM.
- Si el bit vale 0, la p√°gina puede no ser v√°lida, o quiz√°s es v√°lida pero est√° en disco.

Con que sea v√°lida o inv√°lida, nos referimos a que pertenece o no a las direcciones virtuales del proceso respectivamente.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/843cb7bc-a0f9-4fb2-a311-bf177f77bc62/Untitled.png)

**¬øQue pasa si el proceso intenta acceder a una pagina que no est√° en memoria?**

El bit de valid-invalid estar√° en 0 causando una excepci√≥n de **page fault**.

**¬øComo ocurre este page fault?**

Cuando la MMU quiera traducir la direcci√≥n ****a trav√©s de la tabla de p√°ginas, observar√° que el bit V est√° establecido en 0, lo que provoca una excepci√≥n a nivel procesador que despierta al sistema operativo (trap). El sistema operativo reconoce dicho fault y trae la p√°gina que se solicita a memoria.

Las interrupciones de paginado son muy costosas de manejar al requerir accesos a disco, pero es una excepci√≥n continuable (es decir, luego de que la instrucci√≥n falle y se corran los steps que se ven en la imagen, se vuelve a intentar correr la instrucci√≥n que genero la excepci√≥n).

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ff7fe1b7-218f-406d-90b9-d2d8bf682589/Untitled.png)

- Resumen de cada paso
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/316a3948-da91-45e6-9e75-7387714745d8/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/556ef1c1-8e92-457f-8d35-bdba54bb7714/Untitled.png)
    
- Secuencia de pasos en detalle
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/492bc28b-92bf-4d88-995c-3b9cb0a003e8/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3d313ddb-2da5-40f1-b7bf-8ada743bee18/Untitled.png)
    

<aside> ‚ÄºÔ∏è Para traer la p√°gina de memoria secundaria a memoria RAM se ejecuta una operaci√≥n de E/S

</aside>

Podemos notar que una de las propiedades de la paginaci√≥n por demanda es la alta cantidad de _page faults_ que pueden ocurrir cuando un proceso comienza su ejecuci√≥n. Esto se debe a que el proceso quiere ganar localidad en memoria RAM poniendo sus paginas en los distintos marcos.

> _We must solve two major problems to implement demand paging: we must develop a frame-allocation algorithm and a page-replacement algorithm_

# Page replacement algorithms

Si un proceso genera un _page fault_ y el SO se da cuenta que no hay marcos disponibles para traer dicha pagina a RAM, estamos en problemas porque la RAM esta llena.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c6338a3d-f5bd-433e-9250-0cc214817704/Untitled.png)

Terminar al proceso que pidi√≥ la p√°gina no es una buena opci√≥n. Tampoco es una opci√≥n hacer un swap out del proceso o un est√°ndar swapping de p√°ginas por lo que conlleva copiar las p√°ginas de memoria RAM a disco y viceversa. La soluci√≥n es utilizar algoritmos de reemplazo de p√°ginas. Para ello, cuando no hay marcos libres disponibles, se debe elegir una p√°gina v√≠ctima en memoria RAM y enviarla a disco.

## _Overview - Basic page replacement_

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a7a03113-0791-4a89-97e8-06aa54d7f1ef/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b678fd8c-8d47-4672-a2e9-d863e9450af8/Untitled.png)

Notemos que si todos los frames est√°n ocupados, estar√≠amos haciendo dos transferencias de p√°gina. Esta situaci√≥n duplicar√≠a el _page fault service time_ que mencionamos antes e incrementar√≠a el tiempo de acceso efectivo.

Podemos evitar esto haciendo uso del **dirty bit** o **modify bit** que el hardware lo prende si una p√°gina en memoria f√≠sica sufri√≥ alg√∫n cambio en alg√∫n bit. Si una p√°gina fue modificada, no ser√° candidata a ser la v√≠ctima por la simple raz√≥n de que traerla a disco implicar√≠a que escribamos en el los cambios que se produjeron en dicha p√°gina. De esta forma estar√≠amos reduciendo el _page fault service time_ a la mitad si alguna p√°gina en memoria no fue modificada.

<aside> ‚ÄºÔ∏è Es muy costoso sincronizar la escritura en disco. Por eso, solamente tendremos que ‚Äúbajar a disco‚Äù una p√°gina si esta fue modificada y debemos sincronizarla con el disco. En el caso de que la p√°gina sea de solo lectura, podemos bocharla directamente.

</aside>

## Algoritmos de reemplazo de paginas

- _**Optimal:**_ quita las p√°ginas que mas van a tardar en ser usadas en el futuro (si conociera el futuro, pero se puede predecir)
- _**Random:**_ elige una p√°gina al azar
- _**FIFO:**_ saca la primer p√°gina que fue cargada en memoria
- _**LRU:**_ elige una p√°gina que hace m√°s tiempo que no se usa
- Second chance:

Nuestro objetivo es que ocurren la menor cantidad de interrupciones de paginado

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dc6c6c6f-ea67-471e-9a81-76d83447ce04/Untitled.png)

### Optimal

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/867d7a6c-dd5f-46ee-b1e5-aad08fd19bd2/Untitled.png)

El problema es que no podemos predecir el futuro. Descartamos el algoritmo optimo.

### FIFO

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/108225ba-7112-49c9-a522-f8e86b3e2c71/Untitled.png)

El problema de FIFO es que ignora los patrones repetitivos. **Puede** llegar a ocurrir que tengamos mucha tasa de paginado.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/577bfc2d-9151-459f-a739-65330d8a7f3c/Untitled.png)

**Anomal√≠a de Belady:** para algunas secuencias, a menor cantidad de marcos se logra menor tasa de paginado.

### LRU

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/246add9a-7c9d-420e-a32f-0b6fae1d636c/Untitled.png)

LRU es considerado un buen algoritmo. El problema es implementarlo eficientemente. En la pr√°ctica buscaremos una aproximaci√≥n eficiente a LRU llamado algoritmo de segunda oportunidad **o _clock_.

Todas las p√°ginas de un proceso arrancan con el bit de referencia en 0. Cuando alguna p√°gina es referenciada se la marca con 1 (no importa si se referencia multiples veces).

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8dec34d2-b619-4e64-b31c-1d135210332b/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7e74c66e-db6b-4f3d-a8ad-b09b31565171/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bc565a9a-6613-4e48-badf-66b40500b4d4/Untitled.png)

- Pregunta del foro
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d0df7de1-ec0e-4e57-80cf-62673d726d47/Untitled.png)
    

# Trashing o hiperpaginaci√≥n

Definici√≥n importante:

> _**Working set:**_ _The set of pages in the most recent page references._

Supongamos que un proceso necesita m√°s p√°ginas que marcos disponibles presentes en memoria. En otras palabras, no se tiene el n√∫mero m√≠nimo de marcos que necesita para admitir las p√°ginas del working set. Autom√°ticamente se producir√° un _page fault_ que buscara reemplazar alguna p√°gina. Las p√°ginas del working set son p√°ginas activas que necesita el proceso. Entonces, dado que todas las p√°ginas est√°n en uso activo, se estar√°n reemplazando una p√°ginas que se necesitar√°n nuevamente de inmediato. En consecuencia, ocurrir√°n sucesivos page faults r√°pidamente una y otra vez, reemplazando por p√°ginas que se deben traer de vuelta de inmediato.

> _A process is thrashing if it is spending more time paging than executing._

Esto conduce a:

- Alta tasa de interrupciones por paginado
    
- Muchas esperas de E/S de disco
    
- Baja utilizaci√≥n de CPU
    
- No hay trabajo util realizado
    

<aside> üí° Ante un caso de hiperpaginaci√≥n, un CPU mas r√°pido no soluciona el problema, al contrario, lo empeora

</aside>

Para identificar el cuello de botella, podemos utilizar un plano en el eje XYZ donde un punto sobre cada eje representa:

- CPU
- E/S
- Memoria

Hay que tener en claro en cual de estos ejes estamos limitados para evaluar una deficiencia.

**¬øComo podemos limitar los efectos del thrashing?**

Debemos proporcionarle a un proceso tantos marcos como necesite. Pero, ¬øc√≥mo sabemos cu√°ntos marcos necesita? Una estrategia comienza por observar cu√°ntos marcos est√° utilizando realmente un proceso. Este enfoque define el modelo de localidad de ejecuci√≥n de procesos.

El modelo de localidad establece que, a medida que se ejecuta un proceso, este se mueve de localidad en localidad. Una localidad es un conjunto de p√°ginas que se utilizan activamente juntas. Un programa en ejecuci√≥n generalmente se compone de varias localidades diferentes, que pueden superponerse.

- Ejemplo
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4b631a08-6136-41c9-a824-1e5b002ef6a8/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0ab47a17-e867-4b95-9f5d-c15736025544/Untitled.png)
    

> _Suppose we allocate enough frames to a process to accommodate its current locality. It will fault for the pages in its locality until all these pages are in memory; then, it will not fault again until it changes localities. If we do not allocate enough frames to accommodate the size of the current locality, the process will thrash, since it cannot keep in memory all the pages that it is actively using._

# Pre-paginaci√≥n

La pre-paginaci√≥n intenta solucionar la gran cantidad de _page faults_ iniciales que provoca la paginaci√≥n por demanda trayendo a memoria RAM algunas (o todas) las paginas que necesita el proceso de una sola vez.

# Clase Horacio

## Estrategias de paginado

1. Paginaci√≥n a demanda: Se carga la p√°gina como respuesta a la excepci√≥n.
    1. El proceso comienzo sin p√°ginas cargadas.
2. Paginaci√≥n a pedido: el usuario especifica que p√°ginas se necesitan.
    1. Requiere que el usuario maneje la memoria.
3. Prepaginaci√≥n: Se carga la p√°gina antes que sea referenciada. Cuando una p√°gina es referenciada, se trae la siguiente.

Working set (localidad): cantidad de p√°ginas que puedo necesitar para una parte de mi c√≥digo. Cuando tengo una parte de c√≥digo con buena localidad, mi working set va a ser chico, sino grande.

Si el SO sabe cual es mi working set, puede d√°rmela para que yo proceso no sufra de tantas interrupciones de paginado.