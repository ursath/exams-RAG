[
    {
        "user_input": "Gestión y administración de la memoria",
        "retrieved_contexts": [
            "# Memory Manager  \n- ¿Qué parte de la memoria está en uso?\n- Reservar memoria\n- Liberar memoria",
            "### Administrar la memoria libre  \n2 Enfoques:  \n- **Bitmap:** se divide la memoria en bloques y cada bit representa su estado. Si divido en pequeños bloques estonces voy a tener una tabla más grande ya que cada bloque represena un bit en la tabla.\n- **Free list:** cada proceso y espacio libre tiene un nodo con inicio, longitud y el puntero al siguiente. La P quiere decir que hay un proceso, ocupado. La H (Hole) que es memoria libre.\n- Es necesario fusionar bloques libres adyacentes.\n- Doblemente encadenada facilita este trabajo.\n- El orden en la lista es relevante.  \n![Para una misma memoria dividida en bloques, bitmap y free list.](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/44eaefe9-68cc-4484-8aaa-e5b356d3035b/Untitled.png)  \nPara una misma memoria dividida en bloques, bitmap y free list.  \n**¿Cómo buscar un bloque libre?** \nBuscar un bloque libre, luego se parte en 2, lo necesario y lo que sobra (si sobra).  \n- **First fit:** comenzando desde el principio, el primer bloque suficientemente grande → más velocidad.\n- **Next fit:** comenzando desde donde quedamos, el primer bloque suficientemente grande → más velocidad.\n- **Best fit:** recorre toda la lista y elige el bloque más pequeño, pero suficientemente grande → tiende a dejar muchos bloques chiquitos sobrantes → más fragmentación (anti-intuitivo).\n- **Worst fit:** recorre toda la lista y elige el bloque más grande → no resuelve mucho el problema.  \n<aside> ❕ ¡Momento!  \n</aside>  \n- **Free list mejorado:** se pueden separar las listas entre ocupados y libres.\n- Liberar y asignar un bloque consiste en moverlo de listas\n- Puedo ordenar la lista de bloques libres por tamaño (de menor a mayor).\n- Puedo utilizar la misma memoria libre para almacenar la información de su longitud y el puntero a los siguientes bloques de memoria libre. Total nadie la está usando! → No tengo que hacer una segunda lista.\n- **First fit** y **Best fit** se vuelven equivalentes si está ordenada de menor a mayor.\n- **Next fit** no tiene sentido\n- También podemos clasificar los bloques libres por tamaño frecuentemente solicitado.\n- 4 free lists de bloques de 4KB, 8KB, 12KB y 16KB respectivamente.\n- **Quick fit:** el primer bloque de la lista correspondiente.",
            "# Memory Allocation  \n## _Variable partition_  \nUna forma sencilla de asignar memoria a un proceso, es darle pedazos de memoria de tamaño variable. Cada partición o pedazo puede contener exactamente 1 proceso.  \nEl sistema operativo hace uso de una tabla (lista) que contiene la información de las porciones de memoria ocupadas y desocupadas y sus tamaños. Inicialmente, toda la memoria (menos la zona donde se ubico el SO) esta disponible para procesos de usuario.  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a5eff975-ea3a-4b58-b2e5-4e299680170f/Untitled.png)  \nSi la zona de memoria que le asigno a un proceso para que corra es muy grande, esta se parte en dos. Una de las dos es asignada al proceso y la otra parte queda libre. Los agujeros contiguos de memoria se transforman en un solo bloque de memoria disponible.  \n**¿Que hacemos si un proceso no entra? ¿Rechazamos al proceso y listo?** \nEs una opción mientras que respondamos con un mensaje de error adecuado. Sin embargo, una alternativa es utilizar una cola donde en cada asignación de un slot de memoria, el SO chequee si el proceso que esta esperando primero en la cola entra en alguno de los slots de memoria libres.  \nExisten varios algoritmos o estrategias para seleccionar un pedazo de memoria libre de un conjunto de pedazos de memoria libres:  \n- First Fit  \nAsigna memoria del primer hueco que encuentre que es suficientemente grande para el proceso. La búsqueda puede comenzar desde el principio del conjunto (lista) de pedazos de memoria libres o desde donde haya terminado la anterior ejecucion del algoritmo. Podemos finalizar la búsqueda cuando hayamos encontrado un pedazo de memoria lo suficientemente grande.  \n- Best Fit  \nAsigna el pedazo de memoria mas chico que sea suficientemente grande para el proceso. Se busca en toda la lista a no ser que este ordenada por tamaño.  \n- Worst Fit  \nAsigna el pedazo de memoria mas grande. Se busca en toda la lista a no ser que esta ordenada por tamaño.  \n<aside> ‼️ El mas rápido es first fit.  \n</aside>"
        ],
        "response": "## Ejercicios\n\n### 1. Gestión de entrada/salida\n\n**Desarrolle:** \nExplique el rol de los controladores de periféricos en la gestión de entrada/salida dentro de un sistema operativo moderno. Analice cómo la utilización de interrupciones por parte de estos controladores afecta la eficiencia del procesador y la planificación de procesos. Incluya en su respuesta una comparación entre el manejo tradicional de E/S y el manejo actual con controladores, y discuta el impacto de estas técnicas en la concurrencia y el aprovechamiento del CPU.",
        "llm_context_precision_without_reference": 0.0,
        "faithfulness": 0.0,
        "answer_relevancy": 0.7923875320112241
    },
    {
        "user_input": "Concurrencia y sincronización",
        "retrieved_contexts": [
            "# Sincronización de hilos  \n## _Overview_  \nEn este apunte vamos a describir dos métodos que podemos usar para sincronizar los hilos: mutex y variables de condición.  \n**Mutex** permite que los hilos sincronicen su uso de un recurso compartido para que, por ejemplo, un thread no intente acceder a una variable compartida al mismo tiempo que otro thread la modifica.  \nLas **variables de condición** tienen un rol más complementario: permiten que los threads se informen entre sí que una variable compartida (u otro recurso compartido) fue modificada.",
            "# Notas de la clase de Horacio  \n## _Condiciones de carrera usando shared memory_  \n![El valor de counter debería ser 5, pero puede llegar a ser 4 o 6.](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/38fc7cda-3649-4d01-b441-532ae79d9fe3/Untitled.png)  \nEl valor de counter debería ser 5, pero puede llegar a ser 4 o 6.  \nA esta situación se la llama condición de carrera. El resultado es aleatorio y depende del orden en el cual se accede.  \nA esta región donde nos podemos mandar macanas si se hacen ejecuciones concurrentes, se la llama _zona critica_. Tenemos más probabilidad de que ocurra en procesadores multiple core.  \nEl `Kernel` no interviene en el uso de esta memoria compartida, por lo que es necesario algún mecanismo para sincronizar el uso de esa memoria, para evitar, por ejemplo, que un proceso lea memoria mientras otro la esta actualizando como vimos en el ejemplo anterior.  \n¿Cómo podemos solucionar este problema de sincronización en la región critica?  \n_**Exclusión mutua:**_ No más de un proceso en la región crítica a la vez.  \n_**Progreso:**_ Cuando no hay nadie en la región crítica cualquier proceso que quiere ingresar en la región crítica debe ser admitido sin demora.  \n**_No inanición_:** Debe haber un límite superior en la cantidad de veces que un proceso ingresa en la región crítica mientras otro proceso está esperando.",
            "## Race condition  \nUna situación en las que dos o más procesos están leyendo o escribiendo datos compartidos (memoria compartida) y el resultado final depende de quién corre en cada momento.  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c91f7a0d-4322-4e39-a6cf-6b5c5506fee4/Untitled.png)  \n**Región crítica:** parte del programa que accede a la memoria compartida  \n**Solución: exclusión mutua** \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/105e9f7a-22d6-4907-8fb9-fa66d12f5cf1/Untitled.png)"
        ],
        "response": "### 2. Comunicación y sincronización de procesos (IPC)\n\n**Desarrolle:** \nDescriba los dos modelos fundamentales de comunicación entre procesos (memoria compartida y pasaje de mensajes). Analice las ventajas y desventajas de cada uno, e ilustre su explicación con ejemplos concretos de cómo se implementa la sincronización entre procesos utilizando pipes en sistemas UNIX. Explique por qué es importante cerrar los extremos no utilizados de un pipe y qué consecuencias puede tener no hacerlo.",
        "llm_context_precision_without_reference": 0.0,
        "faithfulness": 0.13333333333333333,
        "answer_relevancy": 0.8174711983446904
    },
    {
        "user_input": "Gestión y administración de procesos",
        "retrieved_contexts": [
            "# Procesos  \n## Manejo de procesos  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c9fa10a8-36be-4e70-b7ab-c8ba1d07d673/Untitled.png)  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/208a100f-38c2-4733-8c11-766b15399516/Untitled.png)",
            "## Jerarquia de procesos",
            "## Modelo de procesos  \nTodo software ejecutable se organiza en procesos (secuenciales).  \n**Proceso:** abstracción de programa en ejecución.  \n**Programa:** almacenado en disco, no hace nada"
        ],
        "response": "### 3. Gestión y administración de procesos\n\n**Desarrolle:** \nDefina el concepto de proceso y explique cómo el sistema operativo gestiona la creación y terminación de procesos. Analice la importancia de la jerarquía de procesos y el modelo de procesos en la organización y ejecución de software. Incluya en su respuesta una discusión sobre la diferencia entre un programa y un proceso, y cómo el sistema operativo abstrae y administra estos conceptos.",
        "llm_context_precision_without_reference": 0.3333333333,
        "faithfulness": 0.1111111111111111,
        "answer_relevancy": 0.8550142091475391
    },
    {
        "user_input": "Comunicación y sincronización de procesos (IPC)",
        "retrieved_contexts": [
            "# IPC  \n**Motivación:** \n- Compartir información.\n- Acelerar computación, aprovechar el hardware.\n- Modularidad.\n- Conveniencia.  \n**Dos modelos fundamentales:** \n- Memoria compartida.\n- Pasaje de mensajes.",
            "# Pipes como método de sincronización de procesos  \nVimos que las señales podían usarse como un método de sincronización de acciones entre procesos para evitar condiciones de carrera. Con el siguiente ejemplo, podemos ver como un pipe puede cumplir la misma funcionalidad.  \n- Ejemplo  \nEn este ejemplo un proceso crea multiples procesos distintos. El padre espera a que todos los procesos hijos terminen sus acciones.  \nObservar como los hijos no escriben en el pipe, simplemente, al utilizar el read-end del pipe, el ultimo hijo en forkearse y terminar de ejecutarse es el que le enviara el EOF al padre.  \n> To perform the synchronization, the parent builds a pipe (1) before creating the child processes (2). Each child inherits a file descriptor for the write end of the pipe and closes this descriptor once it has completed its action (3). After all of the children have closed their file descriptors for the write end of the pipe, the parents `read()` (5) from the pipe will complete, returning `end-of-file`. At this point, the parent is free to carry on to do other work. (Note that closing the unused write end of the pipe in the parent (4) is essential to the correct operation of this technique; otherwise, the parent would block forever when trying to read from the pipe.)  \n```c\n#include \"curr_time.h\" /* Declaration of currTime() */\n\nint main(int argc, char *argv[])\n{\nint pfd[2]; /* Process synchronization pipe */\nint j, dummy;\n\nif (argc < 2 || strcmp(argv[1], \"--help\") == 0)\nusageErr(\"%s sleep-time...\\\\n\", argv[0]);\n\nsetbuf(stdout, NULL); /* Make stdout unbuffered, since we\nterminate child with _exit() */\n\nprintf(\"%s Parent started\\\\n\", currTime(\"%T\"));\n\nif (pipe(pfd) == -1) // (1)\nerrExit(\"pipe\");\n\nfor (j = 1; j < argc; j++) {\n\nswitch (fork()) {\n\ncase -1:\nerrExit(\"fork %d\", j);\n\ncase 0: /* Child */\n\nif (close(pfd[0]) == -1) /* Read end is unused */\nerrExit(\"close\");\n\n/* Child does some work, and lets parent know it\\'s done */\nsleep(getInt(argv[j], GN_NONNEG, \"sleep-time\"));\n\n/* Simulate processing */\nprintf(\"%s Child %d (PID=%ld) closing pipe\\\\n\",\ncurrTime(\"%T\"), j, (long) getpid());\n\nif (close(pfd[1]) == -1) // (3)\nerrExit(\"close\");\n\n/* Child now carries on to do other things... */\n_exit(EXIT_SUCCESS);\n\ndefault: /* Parent loops to create next child */\nbreak;\n}\n}\n/* Parent comes here; close write end of pipe so we can see EOF */\n\nif (close(pfd[1]) == -1) /* Write end is unused (4) */\nerrExit(\"close\");\n\n/* Parent may do other work, then synchronizes with children */\nif (read(pfd[0], &dummy, 1) != 0) // (5)\nfatal(\"parent didn\\'t get EOF\");\n\nprintf(\"%s Parent ready to go\\\\n\", currTime(\"%T\"));\n\n/* Parent can now carry on to do other things... */\n\nexit(EXIT_SUCCESS);\n}\n\n```",
            "# Comunicación entre procesos relacionados  \nVeamos un ejemplo donde se muestra como comunicar dos procesos relacionados.  \n- Ejemplo  \n> The main program calls `pipe()` to create a pipe (1), and then calls `fork()` to create a child (2). After the `fork()`, the parent process closes its file descriptor for the read end of the pipe (8), and writes the string given as the programs command-line argument to the write end of the pipe (9). The parent then closes the read end of the pipe (10), and calls `wait()` to wait for the child to terminate (11). After closing its file descriptor for the write end of the pipe (3), the child process enters a loop where it reads (4) blocks of data (of up to `BUF_SIZE` bytes) from the pipe and writes (6) them to standard output. When the child encounters `end-of-file` on the pipe (5), it exits the loop (7), writes a trailing newline character, closes its descriptor for the read end of the pipe, and terminates.  \n```c\n#include <sys/wait.h>\n#define BUF_SIZE 10\n\nint main(int argc, char *argv[])\n{\nint pfd[2]; /* Pipe file descriptors */\nchar buf[BUF_SIZE];\nsize_t numRead;\n\nif (argc != 2 || strcmp(argv[1], \"--help\") == 0)\nusageErr(\"%s string\\\\n\", argv[0]);\n\nif (pipe(pfd) == -1) /* Create the pipe (1)*/\nerrExit(\"pipe\");\n\nswitch (fork()) { // (2)\n\ncase -1:\nerrExit(\"fork\");\n\ncase 0: /* Child - reads from pipe */\n\nif (close(pfd[1]) == -1) /* Write end is unused (3) */\nerrExit(\"close - child\");\n\nfor (;;) { /* Read data from pipe, echo on stdout */\nnumRead = read(pfd[0], buf, BUF_SIZE);\n\nif (numRead == -1)\nerrExit(\"read\");\n\nif (numRead == 0) // (5)\nbreak; /* End-of-file */\n\nif (write(STDOUT_FILENO, buf, numRead) != numRead) // (6)\nfatal(\"child - partial/failed write\");\n}\n\nwrite(STDOUT_FILENO, \"\\\\n\", 1); // (7)\n\nif (close(pfd[0]) == -1) // (8)\nerrExit(\"close\");\n\n_exit(EXIT_SUCCESS);\n\ndefault: /* Parent - writes to pipe */\n\nif (close(pfd[0]) == -1) /* Read end is unused */\nerrExit(\"close - parent\");\n\nif (write(pfd[1], argv[1], strlen(argv[1])) != strlen(argv[1])) // (9)\nfatal(\"parent - partial/failed write\");\n\nif (close(pfd[1]) == -1) /* Child will see EOF (10) */\nerrExit(\"close\");\n\nwait(NULL); /* Wait for child to finish (11) */\n\nexit(EXIT_SUCCESS);\n}\n}\n\n```"
        ],
        "response": "### 4. Concurrencia y sincronización\n\n**Desarrolle:** \nExplique qué es una condición de carrera y cómo puede afectar el resultado de un programa concurrente. Describa el concepto de región crítica y los requisitos que debe cumplir una solución de exclusión mutua. Analice el uso de mutex y variables de condición como mecanismos de sincronización entre hilos, y discuta cómo estos mecanismos previenen problemas de concurrencia. Incluya ejemplos para ilustrar su respuesta.",
        "llm_context_precision_without_reference": 0.0,
        "faithfulness": 0.0,
        "answer_relevancy": 0.7859119507596787
    },
    {
        "user_input": "Gestión de entrada/salida",
        "retrieved_contexts": [
            "# Controladores de periféricos  \n<aside> 🔑  \nLos controladores de los periféricos interrumpen al procesador. Por ejemplo, presiono una tecla del teclado, el controlador del teclado interrumpe al procesador. El controlador del timer tick también.  \n</aside>  \n- Tiempo requerido para acceder a un periférico (acceso a un disco): milisegundos.\n- Tiempo en ejecutar una instrucción: nanosegundos.  \nPor lo tanto, la cantidad de instrucciones que se ejecutan para acceder a un periférico son muchísimas.  \n¿Es necesario que el procesador esté controlando la operación de entrada salida sabiendo que se tarda bastante tiempo?  \nAlgunas operaciones de `I/O`, como accesos a disco, tardan mucho tiempo en realizarse. Antes, los discos precisaban que el `uP` esté constantemente controlando esta operación, pero hoy en día se usan controladores de discos, que básicamente reciben el comando de qué hacer y avisan al `uP` mediante una interrupción cuando la operación terminó.  \nEsto es algo que el scheduler tiene que tomar en cuenta. No tiene sentido que mientras un proceso está esperando algo de `I/O` no pueda correr otro proceso.  \nEntonces, podemos pensar que un proceso está compuesto de ráfagas de `CPU` y hay un tiempo que se dedica a procesos de `I/O`.  \nSi tenemos 3 procesos: P1, P2 y P3, un único core multiproceso, y suponiendo que el scheduler los corre en orden, el esquema de ejecución no es como uno pensaría:  \nP1__P2__P3  \nSe corren de la siguiente forma:  \n|__ cpu(p1) _||_******e/s******_||_ cpu(p1) _||____ e/s_____||_ cpu(p1)_|  \n```\n|__ cpu(p2) _||______e/s______||_ cpu(p2) _|\n```  \nAún cuando tengamos un único core necesitamos un controlador que maneje múltiples procesos. No tenemos manera de switchear o darle el procesador a otra tarea.  \nSi no fuera multiproceso, el procesador quedaría todo en línea:  \n|__ cpu(p1) _||_******e/s******_||_ cpu(p1) _||____ e/s_____||_ cpu(p2)_||____ e/s_____||_ cpu(p2) _|",
            "# Procesos  \n## Manejo de procesos  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c9fa10a8-36be-4e70-b7ab-c8ba1d07d673/Untitled.png)  \n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/208a100f-38c2-4733-8c11-766b15399516/Untitled.png)",
            "# File System  \nQueremos resolver:  \n1. Almacenar mucha información, que quizás no entra en el EDV.\n2. Persistencia luego de la muerte del proceso.\n3. Múltiples procesos accediendo a la misma información.  \n**De nuevo: Abstracciones** \n- Un proceso es una abstracción del CPU.\n- El espacio de direcciones es una abstracción de la memoria.\n- **Los archivos son una abstracción del disco, de hecho , se pueden ver como un espacio de direcciones.** \nLos archivos son administrados por el file system del SO y se encarga de definir cómo serán:  \n- Estructurados\n- Nombrados\n- Accedidos\n- Usados\n- Protegidos\n- Implementados\n- Administrados"
        ],
        "response": "### 5. Gestión y administración de la memoria\n\n**Desarrolle:** \nCompare los enfoques de administración de memoria libre mediante bitmap y free list. Explique cómo funcionan los algoritmos de asignación de memoria (first fit, next fit, best fit, worst fit y quick fit) y analice sus ventajas y desventajas en términos de velocidad y fragmentación. Incluya en su respuesta una discusión sobre la importancia de fusionar bloques libres y cómo la organización de la lista de bloques libres puede influir en la eficiencia de la asignación y liberación de memoria.",
        "llm_context_precision_without_reference": 0.0,
        "faithfulness": 0.0,
        "answer_relevancy": 0.0
    }
]